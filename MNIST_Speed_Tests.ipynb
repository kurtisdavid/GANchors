{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import csgm\n",
    "import dcgan\n",
    "import skimage\n",
    "import anchor_image\n",
    "import image_utils\n",
    "import importlib\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'anchor_image' from '/home/kurtis/Desktop/anchor/ImageAnchors/anchor_image.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(anchor_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {0: [3],\n",
    "        1: [2],\n",
    "        2: [1],\n",
    "        3: [18],\n",
    "        4: [4],\n",
    "        5: [8],\n",
    "        6: [11],\n",
    "        7: [0],\n",
    "        8: [61],\n",
    "        9: [7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = torchvision.datasets.MNIST('./', train=False, transform=lambda x: np.array(x)/255.,\n",
    "                                   target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'dummy': {'dataset': mnist_test, 'dummys': mnist_test},\n",
    "    'batch': {'G': lambda x: dcgan.load_generator(eval=True), 'dataset': mnist_test, 'batch_norm': False},\n",
    "    'batchBN': {'G': lambda x: dcgan.load_generator(eval=False),'dataset': mnist_test, 'batch_norm': True}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = dcgan.Net()\n",
    "net.load_state_dict(torch.load('mnist_cnn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(images):\n",
    "    try:\n",
    "        images = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "    except:\n",
    "        pass\n",
    "    return net(images.view(images.shape[0],1,28,28)).data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = {\n",
    "    key: {i: [] for i in range(10)\n",
    "         }  for key in parameters}\n",
    "\n",
    "precisions = {key:{i: [] for i in range(10)}\n",
    "                 for key in parameters\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectData(parameter, times, precisions, n_trials = 1):\n",
    "    currTime = times[parameter]\n",
    "    currPrecision = precisions[parameter]\n",
    "    for c in samples:\n",
    "        sample = samples[c][0]\n",
    "        for i in range(n_trials):\n",
    "            image = mnist_test[sample][0]\n",
    "            explainer = anchor_image.AnchorImageMNIST([],'yeet', **parameters[parameter])\n",
    "            start = time.time()\n",
    "            segments, exp = explainer.explain_instance(image,predict_fn,verbose=True)\n",
    "            end = time.time()\n",
    "            currTime[c].append(end-start)\n",
    "            currPrecision[c].append(exp)\n",
    "            with open(parameter+'_times.pck','wb') as f:\n",
    "                pickle.dump(currTime,f)\n",
    "            with open(parameter+'_precisions.pck','wb') as f:\n",
    "                pickle.dump(currPrecision,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = 'dummy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found max_dist of  3  created  15  segments\n",
      "True pred 0\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 17 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 26 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 34 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 2 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 12 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 4 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 30 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 10 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 27 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 13 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 11 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 29 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 25 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 20 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 31 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 26 (mean:0.5445544554, n: 101, lb:0.2696) Worst: 32 (mean:0.0000, n: 1, ub:1.0000) B = 0.73\n",
      "Best: 26 (mean:0.4825870647, n: 201, lb:0.2870) Worst: 22 (mean:0.0000, n: 1, ub:1.0000) B = 0.71\n",
      "Best: 26 (mean:0.4817275748, n: 301, lb:0.3190) Worst: 21 (mean:0.0000, n: 1, ub:1.0000) B = 0.68\n",
      "Best: 26 (mean:0.5012468828, n: 401, lb:0.3575) Worst: 24 (mean:0.0000, n: 1, ub:1.0000) B = 0.64\n",
      "Best: 26 (mean:0.5169660679, n: 501, lb:0.3869) Worst: 23 (mean:0.0000, n: 1, ub:1.0000) B = 0.61\n",
      "Best: 26 (mean:0.5324459235, n: 601, lb:0.4127) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 0.59\n",
      "Best: 26 (mean:0.5292439372, n: 701, lb:0.4180) Worst: 19 (mean:0.0000, n: 1, ub:1.0000) B = 0.58\n",
      "Best: 26 (mean:0.5330836454, n: 801, lb:0.4286) Worst: 3 (mean:0.0000, n: 1, ub:1.0000) B = 0.57\n",
      "Best: 26 (mean:0.5338512764, n: 901, lb:0.4351) Worst: 18 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5334665335, n: 1001, lb:0.4396) Worst: 33 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5349682107, n: 1101, lb:0.4452) Worst: 5 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5303913405, n: 1201, lb:0.4443) Worst: 9 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5303612606, n: 1301, lb:0.4475) Worst: 16 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5310492505, n: 1401, lb:0.4511) Worst: 15 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5303131246, n: 1501, lb:0.4529) Worst: 6 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5302935665, n: 1601, lb:0.4552) Worst: 7 (mean:0.0000, n: 1, ub:1.0000) B = 0.54\n",
      "Best: 26 (mean:0.5332157554, n: 1701, lb:0.4603) Worst: 8 (mean:0.0000, n: 1, ub:1.0000) B = 0.54\n",
      "Best: 26 (mean:0.5358134370, n: 1801, lb:0.4648) Worst: 28 (mean:0.0000, n: 1, ub:1.0000) B = 0.54\n",
      "Best: 26 (mean:0.5328774329, n: 1901, lb:0.4637) Worst: 14 (mean:0.0000, n: 1, ub:1.0000) B = 0.54\n",
      "Best: 26 (mean:0.5317341329, n: 2001, lb:0.4642) Worst: 18 (mean:0.3168, n: 101, ub:0.6144) B = 0.15\n",
      "Best of size  1 :\n",
      "26 0.5273679200380771 0.5039669421591872 0.5506892444372986\n",
      "(26,) mean = 0.53 lb = 0.50 ub = 0.55 coverage: 0.53 n: 2101\n",
      "Making tuples...\n",
      "Best of size  2 :\n",
      "7 0.8637532133676092 0.8236229774419943 0.8981647889847708\n",
      "(18, 26) mean = 0.86 lb = 0.82 ub = 0.90 coverage: 0.26 n: 389\n",
      "Making tuples...\n",
      "Best: 22 (mean:1.0000000000, n: 79, lb:0.8347) Worst: 13 (mean:0.9605, n: 76, ub:0.9999) B = 0.17\n",
      "Best of size  3 :\n",
      "22 1.0 0.9872181167987083 1\n",
      "(8, 18, 26) mean = 1.00 lb = 0.99 ub = 1.00 coverage: 0.11 n: 179\n",
      "Found eligible anchor  (8, 18, 26) Coverage: 0.11 Is best? True\n",
      "found max_dist of  3  created  15  segments\n",
      "True pred 0\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 18 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 13 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 17 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 4 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 34 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 30 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 14 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 5 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 15 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 18 (mean:0.3168316832, n: 101, lb:0.1061) Worst: 26 (mean:0.0000, n: 1, ub:1.0000) B = 0.89\n",
      "Best: 26 (mean:0.5445544554, n: 101, lb:0.2717) Worst: 29 (mean:0.0000, n: 1, ub:1.0000) B = 0.73\n",
      "Best: 26 (mean:0.5273631841, n: 201, lb:0.3286) Worst: 12 (mean:0.0000, n: 1, ub:1.0000) B = 0.67\n",
      "Best: 26 (mean:0.5348837209, n: 301, lb:0.3696) Worst: 24 (mean:0.0000, n: 1, ub:1.0000) B = 0.63\n",
      "Best: 26 (mean:0.5411471322, n: 401, lb:0.3965) Worst: 11 (mean:0.0000, n: 1, ub:1.0000) B = 0.60\n",
      "Best: 26 (mean:0.5309381238, n: 501, lb:0.4011) Worst: 22 (mean:0.0000, n: 1, ub:1.0000) B = 0.60\n",
      "Best: 26 (mean:0.5291181364, n: 601, lb:0.4100) Worst: 10 (mean:0.0000, n: 1, ub:1.0000) B = 0.59\n",
      "Best: 26 (mean:0.5320970043, n: 701, lb:0.4213) Worst: 20 (mean:0.0000, n: 1, ub:1.0000) B = 0.58\n",
      "Best: 26 (mean:0.5380774032, n: 801, lb:0.4340) Worst: 9 (mean:0.0000, n: 1, ub:1.0000) B = 0.57\n",
      "Best: 26 (mean:0.5371809101, n: 901, lb:0.4388) Worst: 19 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5374625375, n: 1001, lb:0.4439) Worst: 31 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5367847411, n: 1101, lb:0.4473) Worst: 8 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5303913405, n: 1201, lb:0.4446) Worst: 28 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5219062260, n: 1301, lb:0.4394) Worst: 25 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5274803712, n: 1401, lb:0.4478) Worst: 16 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5276482345, n: 1501, lb:0.4505) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5252966896, n: 1601, lb:0.4505) Worst: 2 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5308641975, n: 1701, lb:0.4581) Worst: 3 (mean:0.0000, n: 1, ub:1.0000) B = 0.54\n",
      "Best: 26 (mean:0.5347029428, n: 1801, lb:0.4639) Worst: 32 (mean:0.0000, n: 1, ub:1.0000) B = 0.54\n",
      "Best: 26 (mean:0.5334034719, n: 1901, lb:0.4644) Worst: 23 (mean:0.0000, n: 1, ub:1.0000) B = 0.54\n",
      "Best: 26 (mean:0.5322338831, n: 2001, lb:0.4649) Worst: 27 (mean:0.0000, n: 1, ub:1.0000) B = 0.54\n",
      "Best: 26 (mean:0.5330794860, n: 2101, lb:0.4673) Worst: 21 (mean:0.0000, n: 1, ub:1.0000) B = 0.53\n",
      "Best: 26 (mean:0.5329395729, n: 2201, lb:0.4686) Worst: 33 (mean:0.0000, n: 1, ub:1.0000) B = 0.53\n",
      "Best: 26 (mean:0.5367231638, n: 2301, lb:0.4737) Worst: 7 (mean:0.0000, n: 1, ub:1.0000) B = 0.53\n",
      "Best: 26 (mean:0.5376926281, n: 2401, lb:0.4759) Worst: 6 (mean:0.0000, n: 1, ub:1.0000) B = 0.52\n",
      "Best of size  1 :\n",
      "26 0.53218712514994 0.5107464877651153 0.5535488632415834\n",
      "(26,) mean = 0.53 lb = 0.51 ub = 0.55 coverage: 0.45 n: 2501\n",
      "Making tuples...\n",
      "Best of size  2 :\n",
      "7 0.8824742268041237 0.8487074834880057 0.9114153441654876\n",
      "(18, 26) mean = 0.88 lb = 0.85 ub = 0.91 coverage: 0.19 n: 485\n",
      "Making tuples...\n",
      "Best of size  3 :\n",
      "22 1.0 0.9781016891394232 1\n",
      "(8, 18, 26) mean = 1.00 lb = 0.98 ub = 1.00 coverage: 0.09 n: 104\n",
      "Found eligible anchor  (8, 18, 26) Coverage: 0.09 Is best? True\n",
      "found max_dist of  3  created  15  segments\n",
      "True pred 0\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 32 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 4 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 17 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 26 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 34 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 15 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 13 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 21 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 30 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 26 (mean:0.5148514851, n: 101, lb:0.2483) Worst: 12 (mean:0.0000, n: 1, ub:1.0000) B = 0.75\n",
      "Best: 26 (mean:0.5024875622, n: 201, lb:0.3069) Worst: 29 (mean:0.0000, n: 1, ub:1.0000) B = 0.69\n",
      "Best: 26 (mean:0.5016611296, n: 301, lb:0.3390) Worst: 11 (mean:0.0000, n: 1, ub:1.0000) B = 0.66\n",
      "Best: 26 (mean:0.4912718204, n: 401, lb:0.3495) Worst: 23 (mean:0.0000, n: 1, ub:1.0000) B = 0.65\n",
      "Best: 26 (mean:0.4790419162, n: 501, lb:0.3518) Worst: 22 (mean:0.0000, n: 1, ub:1.0000) B = 0.65\n",
      "Best: 26 (mean:0.4891846922, n: 601, lb:0.3718) Worst: 10 (mean:0.0000, n: 1, ub:1.0000) B = 0.63\n",
      "Best: 26 (mean:0.4821683310, n: 701, lb:0.3732) Worst: 28 (mean:0.0000, n: 1, ub:1.0000) B = 0.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 26 (mean:0.4818976280, n: 801, lb:0.3795) Worst: 9 (mean:0.0000, n: 1, ub:1.0000) B = 0.62\n",
      "Best: 26 (mean:0.4805771365, n: 901, lb:0.3837) Worst: 27 (mean:0.0000, n: 1, ub:1.0000) B = 0.62\n",
      "Best: 26 (mean:0.4895104895, n: 1001, lb:0.3970) Worst: 8 (mean:0.0000, n: 1, ub:1.0000) B = 0.60\n",
      "Best: 26 (mean:0.4895549500, n: 1101, lb:0.4011) Worst: 25 (mean:0.0000, n: 1, ub:1.0000) B = 0.60\n",
      "Best: 26 (mean:0.4870940883, n: 1201, lb:0.4022) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 0.60\n",
      "Best: 26 (mean:0.4911606457, n: 1301, lb:0.4093) Worst: 31 (mean:0.0000, n: 1, ub:1.0000) B = 0.59\n",
      "Best: 26 (mean:0.4910778016, n: 1401, lb:0.4120) Worst: 24 (mean:0.0000, n: 1, ub:1.0000) B = 0.59\n",
      "Best: 26 (mean:0.5016655563, n: 1501, lb:0.4249) Worst: 20 (mean:0.0000, n: 1, ub:1.0000) B = 0.58\n",
      "Best: 26 (mean:0.5046845721, n: 1601, lb:0.4302) Worst: 19 (mean:0.0000, n: 1, ub:1.0000) B = 0.57\n",
      "Best: 26 (mean:0.5102880658, n: 1701, lb:0.4378) Worst: 18 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5102720711, n: 1801, lb:0.4397) Worst: 33 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5107837980, n: 1901, lb:0.4420) Worst: 16 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5117441279, n: 2001, lb:0.4446) Worst: 2 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5097572584, n: 2101, lb:0.4442) Worst: 14 (mean:0.0000, n: 1, ub:1.0000) B = 0.56\n",
      "Best: 26 (mean:0.5093139482, n: 2201, lb:0.4451) Worst: 3 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5102129509, n: 2301, lb:0.4474) Worst: 7 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5102040816, n: 2401, lb:0.4486) Worst: 6 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5097960816, n: 2501, lb:0.4494) Worst: 5 (mean:0.0000, n: 1, ub:1.0000) B = 0.55\n",
      "Best: 26 (mean:0.5082660515, n: 2601, lb:0.4489) Worst: 18 (mean:0.3762, n: 101, ub:0.6715) B = 0.22\n",
      "Best of size  1 :\n",
      "26 0.5116623472787857 0.49101754758227595 0.5322806845338611\n",
      "(26,) mean = 0.51 lb = 0.49 ub = 0.53 coverage: 0.58 n: 2701\n",
      "Making tuples...\n",
      "Best of size  2 :\n",
      "7 0.8738049713193117 0.8404869563735373 0.902748023559965\n",
      "(18, 26) mean = 0.87 lb = 0.84 ub = 0.90 coverage: 0.27 n: 523\n",
      "Making tuples...\n",
      "Best of size  3 :\n",
      "22 1.0 0.9781016891394232 1\n",
      "(8, 18, 26) mean = 1.00 lb = 0.98 ub = 1.00 coverage: 0.20 n: 104\n",
      "Found eligible anchor  (8, 18, 26) Coverage: 0.2 Is best? True\n",
      "found max_dist of  3  created  15  segments\n",
      "True pred 1\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 3 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 3 (mean:0.2475247525, n: 101, lb:0.0741) Worst: 8 (mean:0.0000, n: 1, ub:1.0000) B = 0.93\n",
      "Best: 3 (mean:0.2288557214, n: 201, lb:0.0975) Worst: 16 (mean:0.0000, n: 1, ub:1.0000) B = 0.90\n",
      "Best: 3 (mean:0.2358803987, n: 301, lb:0.1209) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 0.88\n",
      "Best: 3 (mean:0.2394014963, n: 401, lb:0.1358) Worst: 14 (mean:0.0000, n: 1, ub:1.0000) B = 0.86\n",
      "Best: 3 (mean:0.2395209581, n: 501, lb:0.1448) Worst: 13 (mean:0.0000, n: 1, ub:1.0000) B = 0.86\n",
      "Best: 3 (mean:0.2462562396, n: 601, lb:0.1571) Worst: 12 (mean:0.0000, n: 1, ub:1.0000) B = 0.84\n",
      "Best: 3 (mean:0.2482168331, n: 701, lb:0.1643) Worst: 11 (mean:0.0000, n: 1, ub:1.0000) B = 0.84\n",
      "Best: 3 (mean:0.2409488140, n: 801, lb:0.1626) Worst: 10 (mean:0.0000, n: 1, ub:1.0000) B = 0.84\n",
      "Best: 3 (mean:0.2519422863, n: 901, lb:0.1759) Worst: 9 (mean:0.0000, n: 1, ub:1.0000) B = 0.82\n",
      "Best: 3 (mean:0.2557442557, n: 1001, lb:0.1826) Worst: 15 (mean:0.0000, n: 1, ub:1.0000) B = 0.82\n",
      "Best: 3 (mean:0.2543142598, n: 1101, lb:0.1843) Worst: 7 (mean:0.0000, n: 1, ub:1.0000) B = 0.82\n",
      "Best: 3 (mean:0.2514571191, n: 1201, lb:0.1843) Worst: 6 (mean:0.0000, n: 1, ub:1.0000) B = 0.82\n",
      "Best: 3 (mean:0.2490392006, n: 1301, lb:0.1844) Worst: 2 (mean:0.0000, n: 1, ub:1.0000) B = 0.82\n",
      "Best: 3 (mean:0.2448251249, n: 1401, lb:0.1827) Worst: 5 (mean:0.0000, n: 1, ub:1.0000) B = 0.82\n",
      "Best: 3 (mean:0.2458361093, n: 1501, lb:0.1854) Worst: 4 (mean:0.0000, n: 1, ub:1.0000) B = 0.81\n",
      "Best: 3 (mean:0.2460961899, n: 1601, lb:0.1873) Worst: 5 (mean:0.2178, n: 101, ub:0.4986) B = 0.31\n",
      "Best: 3 (mean:0.2492651382, n: 1701, lb:0.1917) Worst: 15 (mean:0.1881, n: 101, ub:0.4648) B = 0.27\n",
      "Best: 3 (mean:0.2493059411, n: 1801, lb:0.1932) Worst: 10 (mean:0.1683, n: 101, ub:0.4414) B = 0.25\n",
      "Best: 3 (mean:0.2503945292, n: 1901, lb:0.1955) Worst: 2 (mean:0.1683, n: 101, ub:0.4420) B = 0.25\n",
      "Best: 3 (mean:0.2453773113, n: 2001, lb:0.1921) Worst: 7 (mean:0.1584, n: 101, ub:0.4302) B = 0.24\n",
      "Best: 3 (mean:0.2460732984, n: 2101, lb:0.1939) Worst: 13 (mean:0.1485, n: 101, ub:0.4181) B = 0.22\n",
      "Best: 3 (mean:0.2448886870, n: 2201, lb:0.1939) Worst: 1 (mean:0.1287, n: 101, ub:0.3928) B = 0.20\n",
      "Best: 3 (mean:0.2451108214, n: 2301, lb:0.1950) Worst: 11 (mean:0.1287, n: 101, ub:0.3932) B = 0.20\n",
      "Best: 3 (mean:0.2432319867, n: 2401, lb:0.1942) Worst: 5 (mean:0.1990, n: 201, ub:0.3926) B = 0.20\n",
      "Best: 3 (mean:0.2431027589, n: 2501, lb:0.1950) Worst: 15 (mean:0.1990, n: 201, ub:0.3929) B = 0.20\n",
      "Best: 3 (mean:0.2410611303, n: 2601, lb:0.1939) Worst: 13 (mean:0.1891, n: 201, ub:0.3814) B = 0.19\n",
      "Best: 3 (mean:0.2413920770, n: 2701, lb:0.1950) Worst: 4 (mean:0.1089, n: 101, ub:0.3678) B = 0.17\n",
      "Best: 3 (mean:0.2456265619, n: 2801, lb:0.1997) Worst: 14 (mean:0.1089, n: 101, ub:0.3681) B = 0.17\n",
      "Best: 3 (mean:0.2454326094, n: 2901, lb:0.2002) Worst: 2 (mean:0.1692, n: 201, ub:0.3581) B = 0.16\n",
      "Best: 3 (mean:0.2459180273, n: 3001, lb:0.2013) Worst: 9 (mean:0.0990, n: 101, ub:0.3548) B = 0.15\n",
      "Best: 3 (mean:0.2457271848, n: 3101, lb:0.2018) Worst: 12 (mean:0.0990, n: 101, ub:0.3551) B = 0.15\n",
      "Best of size  1 :\n",
      "3 0.2436738519212746 0.2276412739512701 0.26019808828470614\n",
      "(3,) mean = 0.24 lb = 0.23 ub = 0.26 coverage: 0.49 n: 3201\n",
      "Making tuples...\n",
      "Best: 2 (mean:0.3219284603, n: 643, lb:0.2321) Worst: 6 (mean:0.3123, n: 650, ub:0.4109) B = 0.18\n",
      "Best: 6 (mean:0.3213333333, n: 750, lb:0.2354) Worst: 2 (mean:0.3163, n: 743, ub:0.4114) B = 0.18\n",
      "Best: 6 (mean:0.3211764706, n: 850, lb:0.2389) Worst: 15 (mean:0.2952, n: 630, ub:0.3994) B = 0.16\n",
      "Best: 6 (mean:0.3168421053, n: 950, lb:0.2382) Worst: 2 (mean:0.3084, n: 843, ub:0.3998) B = 0.16\n",
      "Best: 2 (mean:0.3191940615, n: 943, lb:0.2395) Worst: 15 (mean:0.3014, n: 730, ub:0.4002) B = 0.16\n",
      "Best: 2 (mean:0.3202301055, n: 1043, lb:0.2436) Worst: 15 (mean:0.3060, n: 830, ub:0.3995) B = 0.16\n",
      "Best: 2 (mean:0.3132108486, n: 1143, lb:0.2400) Worst: 6 (mean:0.3124, n: 1050, ub:0.3960) B = 0.16\n",
      "Best: 6 (mean:0.3147826087, n: 1150, lb:0.2413) Worst: 15 (mean:0.3054, n: 930, ub:0.3944) B = 0.15\n",
      "Best of size  2 :\n",
      "6 0.312 0.2843632656611007 0.3405591937022219\n",
      "(3, 8) mean = 0.31 lb = 0.28 ub = 0.34 coverage: 0.29 n: 1250\n",
      "Making tuples...\n",
      "Best: 6 (mean:0.4377510040, n: 249, lb:0.2835) Worst: 11 (mean:0.4089, n: 247, ub:0.5731) B = 0.29\n",
      "Best: 6 (mean:0.4383954155, n: 349, lb:0.3027) Worst: 14 (mean:0.3855, n: 249, ub:0.5541) B = 0.25\n",
      "Best: 6 (mean:0.4476614699, n: 449, lb:0.3246) Worst: 10 (mean:0.3794, n: 253, ub:0.5495) B = 0.22\n",
      "Best: 6 (mean:0.4499089253, n: 549, lb:0.3367) Worst: 11 (mean:0.3948, n: 347, ub:0.5418) B = 0.21\n",
      "Best: 6 (mean:0.4530046225, n: 649, lb:0.3475) Worst: 14 (mean:0.3926, n: 349, ub:0.5404) B = 0.19\n",
      "Best: 6 (mean:0.4539385848, n: 749, lb:0.3548) Worst: 14 (mean:0.4187, n: 449, ub:0.5500) B = 0.20\n",
      "Best: 6 (mean:0.4534746761, n: 849, lb:0.3596) Worst: 13 (mean:0.3640, n: 250, ub:0.5406) B = 0.18\n",
      "Best: 6 (mean:0.4552160169, n: 949, lb:0.3658) Worst: 14 (mean:0.4189, n: 549, ub:0.5391) B = 0.17\n",
      "Best: 6 (mean:0.4509056244, n: 1049, lb:0.3656) Worst: 14 (mean:0.4237, n: 649, ub:0.5347) B = 0.17\n",
      "Best: 6 (mean:0.4525674500, n: 1149, lb:0.3706) Worst: 7 (mean:0.3534, n: 249, ub:0.5326) B = 0.16\n",
      "Best of size  3 :\n",
      "6 0.45316253002401924 0.4230779480735877 0.48347735584924867\n",
      "(3, 8, 12) mean = 0.45 lb = 0.42 ub = 0.48 coverage: 0.14 n: 1249\n",
      "Could not find an anchor, now doing best of each size\n",
      "found max_dist of  3  created  15  segments\n",
      "True pred 1\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 7 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 6 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 8 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 7 (mean:0.1386138614, n: 101, lb:0.0217) Worst: 16 (mean:0.0000, n: 1, ub:1.0000) B = 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 16 (mean:0.1683168317, n: 101, lb:0.0326) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 0.97\n",
      "Best: 1 (mean:0.1683168317, n: 101, lb:0.0320) Worst: 14 (mean:0.0000, n: 1, ub:1.0000) B = 0.97\n",
      "Best: 1 (mean:0.1890547264, n: 201, lb:0.0693) Worst: 13 (mean:0.0000, n: 1, ub:1.0000) B = 0.93\n",
      "Best: 1 (mean:0.1860465116, n: 301, lb:0.0833) Worst: 12 (mean:0.0000, n: 1, ub:1.0000) B = 0.92\n",
      "Best: 1 (mean:0.1745635910, n: 401, lb:0.0855) Worst: 2 (mean:0.0000, n: 1, ub:1.0000) B = 0.91\n",
      "Best: 1 (mean:0.1596806387, n: 501, lb:0.0819) Worst: 11 (mean:0.0000, n: 1, ub:1.0000) B = 0.92\n",
      "Best: 1 (mean:0.1597337770, n: 601, lb:0.0872) Worst: 10 (mean:0.0000, n: 1, ub:1.0000) B = 0.91\n",
      "Best: 10 (mean:0.1881188119, n: 101, lb:0.0382) Worst: 9 (mean:0.0000, n: 1, ub:1.0000) B = 0.96\n",
      "Best: 16 (mean:0.1592039801, n: 201, lb:0.0498) Worst: 3 (mean:0.0000, n: 1, ub:1.0000) B = 0.95\n",
      "Best: 3 (mean:0.1980198020, n: 101, lb:0.0420) Worst: 15 (mean:0.0000, n: 1, ub:1.0000) B = 0.96\n",
      "Best: 3 (mean:0.2139303483, n: 201, lb:0.0821) Worst: 4 (mean:0.0000, n: 1, ub:1.0000) B = 0.92\n",
      "Best: 3 (mean:0.1993355482, n: 301, lb:0.0902) Worst: 5 (mean:0.0000, n: 1, ub:1.0000) B = 0.91\n",
      "Best: 3 (mean:0.2069825436, n: 401, lb:0.1074) Worst: 5 (mean:0.1782, n: 101, ub:0.4517) B = 0.34\n",
      "Best: 3 (mean:0.2095808383, n: 501, lb:0.1180) Worst: 2 (mean:0.1584, n: 101, ub:0.4280) B = 0.31\n",
      "Best: 3 (mean:0.2129783694, n: 601, lb:0.1273) Worst: 11 (mean:0.1485, n: 101, ub:0.4160) B = 0.29\n",
      "Best: 3 (mean:0.2125534950, n: 701, lb:0.1324) Worst: 14 (mean:0.1386, n: 101, ub:0.4038) B = 0.27\n",
      "Best: 3 (mean:0.2209737828, n: 801, lb:0.1438) Worst: 15 (mean:0.1287, n: 101, ub:0.3913) B = 0.25\n",
      "Best: 3 (mean:0.2186459489, n: 901, lb:0.1456) Worst: 13 (mean:0.1287, n: 101, ub:0.3918) B = 0.25\n",
      "Best: 3 (mean:0.2187812188, n: 1001, lb:0.1490) Worst: 4 (mean:0.1287, n: 101, ub:0.3923) B = 0.24\n",
      "Best: 3 (mean:0.2261580381, n: 1101, lb:0.1582) Worst: 9 (mean:0.1188, n: 101, ub:0.3794) B = 0.22\n",
      "Best: 3 (mean:0.2231473772, n: 1201, lb:0.1581) Worst: 6 (mean:0.1188, n: 101, ub:0.3799) B = 0.22\n",
      "Best: 3 (mean:0.2221368178, n: 1301, lb:0.1595) Worst: 0 (mean:0.1188, n: 101, ub:0.3803) B = 0.22\n",
      "Best: 3 (mean:0.2241256246, n: 1401, lb:0.1632) Worst: 5 (mean:0.1791, n: 201, ub:0.3692) B = 0.21\n",
      "Best: 3 (mean:0.2265156562, n: 1501, lb:0.1672) Worst: 8 (mean:0.1089, n: 101, ub:0.3674) B = 0.20\n",
      "Best: 3 (mean:0.2273579013, n: 1601, lb:0.1696) Worst: 12 (mean:0.0891, n: 101, ub:0.3392) B = 0.17\n",
      "Best: 3 (mean:0.2286890065, n: 1701, lb:0.1723) Worst: 15 (mean:0.1542, n: 201, ub:0.3393) B = 0.17\n",
      "Best: 3 (mean:0.2309827873, n: 1801, lb:0.1758) Worst: 2 (mean:0.1542, n: 201, ub:0.3396) B = 0.16\n",
      "Best: 3 (mean:0.2283008943, n: 1901, lb:0.1747) Worst: 7 (mean:0.1542, n: 201, ub:0.3398) B = 0.17\n",
      "Best: 3 (mean:0.2278860570, n: 2001, lb:0.1755) Worst: 10 (mean:0.1443, n: 201, ub:0.3274) B = 0.15\n",
      "Best: 3 (mean:0.2279866730, n: 2101, lb:0.1768) Worst: 14 (mean:0.1443, n: 201, ub:0.3276) B = 0.15\n",
      "Best of size  1 :\n",
      "3 0.2303498409813721 0.21147375934761958 0.2499776296135735\n",
      "(3,) mean = 0.23 lb = 0.21 ub = 0.25 coverage: 0.56 n: 2201\n",
      "Making tuples...\n",
      "Best: 6 (mean:0.3067484663, n: 489, lb:0.2068) Worst: 2 (mean:0.3013, n: 385, ub:0.4299) B = 0.22\n",
      "Best: 2 (mean:0.3134020619, n: 485, lb:0.2094) Worst: 10 (mean:0.2971, n: 441, ub:0.4204) B = 0.21\n",
      "Best: 6 (mean:0.2988115450, n: 589, lb:0.2040) Worst: 15 (mean:0.2955, n: 440, ub:0.4210) B = 0.22\n",
      "Best: 2 (mean:0.2957264957, n: 585, lb:0.2000) Worst: 15 (mean:0.2815, n: 540, ub:0.3947) B = 0.19\n",
      "Best: 15 (mean:0.2968750000, n: 640, lb:0.2041) Worst: 2 (mean:0.2964, n: 685, ub:0.3982) B = 0.19\n",
      "Best: 15 (mean:0.3081081081, n: 740, lb:0.2195) Worst: 12 (mean:0.2670, n: 442, ub:0.3935) B = 0.17\n",
      "Best: 15 (mean:0.3095238095, n: 840, lb:0.2253) Worst: 6 (mean:0.2903, n: 689, ub:0.3928) B = 0.17\n",
      "Best: 15 (mean:0.3085106383, n: 940, lb:0.2283) Worst: 6 (mean:0.2991, n: 789, ub:0.3957) B = 0.17\n",
      "Best: 6 (mean:0.3127109111, n: 889, lb:0.2297) Worst: 15 (mean:0.3106, n: 1040, ub:0.3953) B = 0.17\n",
      "Best: 6 (mean:0.3124368049, n: 989, lb:0.2332) Worst: 10 (mean:0.2773, n: 541, ub:0.3942) B = 0.16\n",
      "Best: 6 (mean:0.3158861341, n: 1089, lb:0.2396) Worst: 15 (mean:0.3114, n: 1140, ub:0.3929) B = 0.15\n",
      "Best of size  2 :\n",
      "6 0.31791421362489486 0.28942927230192644 0.3473383337373157\n",
      "(3, 8) mean = 0.32 lb = 0.29 ub = 0.35 coverage: 0.26 n: 1189\n",
      "Making tuples...\n",
      "Best: 14 (mean:0.4703557312, n: 253, lb:0.3141) Worst: 11 (mean:0.4492, n: 256, ub:0.6096) B = 0.30\n",
      "Best: 11 (mean:0.4522471910, n: 356, lb:0.3167) Worst: 6 (mean:0.3965, n: 227, ub:0.5729) B = 0.26\n",
      "Best: 11 (mean:0.4736842105, n: 456, lb:0.3499) Worst: 6 (mean:0.4128, n: 327, ub:0.5625) B = 0.21\n",
      "Best: 11 (mean:0.4694244604, n: 556, lb:0.3559) Worst: 5 (mean:0.3805, n: 226, ub:0.5624) B = 0.21\n",
      "Best: 11 (mean:0.4573170732, n: 656, lb:0.3522) Worst: 14 (mean:0.4108, n: 353, ub:0.5578) B = 0.21\n",
      "Best: 11 (mean:0.4603174603, n: 756, lb:0.3613) Worst: 6 (mean:0.4145, n: 427, ub:0.5492) B = 0.19\n",
      "Best: 11 (mean:0.4567757009, n: 856, lb:0.3632) Worst: 6 (mean:0.4326, n: 527, ub:0.5546) B = 0.19\n",
      "Best: 11 (mean:0.4581589958, n: 956, lb:0.3690) Worst: 6 (mean:0.4306, n: 627, ub:0.5430) B = 0.17\n",
      "Best: 11 (mean:0.4535984848, n: 1056, lb:0.3684) Worst: 8 (mean:0.3543, n: 223, ub:0.5429) B = 0.17\n",
      "Best: 11 (mean:0.4446366782, n: 1156, lb:0.3632) Worst: 9 (mean:0.3583, n: 254, ub:0.5358) B = 0.17\n",
      "Best: 11 (mean:0.4410828025, n: 1256, lb:0.3627) Worst: 2 (mean:0.3478, n: 230, ub:0.5348) B = 0.17\n",
      "Best: 11 (mean:0.4358407080, n: 1356, lb:0.3603) Worst: 6 (mean:0.4264, n: 727, ub:0.5324) B = 0.17\n",
      "Best: 6 (mean:0.4304715840, n: 827, lb:0.3345) Worst: 3 (mean:0.3458, n: 240, ub:0.5299) B = 0.20\n",
      "Best: 6 (mean:0.4347357066, n: 927, lb:0.3434) Worst: 14 (mean:0.3929, n: 453, ub:0.5277) B = 0.18\n",
      "Best: 6 (mean:0.4371957157, n: 1027, lb:0.3500) Worst: 4 (mean:0.3377, n: 228, ub:0.5274) B = 0.18\n",
      "Best: 6 (mean:0.4312333629, n: 1127, lb:0.3479) Worst: 8 (mean:0.3622, n: 323, ub:0.5223) B = 0.17\n",
      "Best: 6 (mean:0.4335778321, n: 1227, lb:0.3534) Worst: 9 (mean:0.3616, n: 354, ub:0.5147) B = 0.16\n",
      "Best: 6 (mean:0.4302938960, n: 1327, lb:0.3531) Worst: 13 (mean:0.3217, n: 230, ub:0.5113) B = 0.16\n",
      "Best of size  3 :\n",
      "6 0.43587946741415556 0.40787021705907744 0.4641643677998074\n",
      "(3, 8, 12) mean = 0.44 lb = 0.41 ub = 0.46 coverage: 0.10 n: 1427\n",
      "Could not find an anchor, now doing best of each size\n",
      "found max_dist of  3  created  15  segments\n",
      "True pred 1\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 15 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 0 (mean:0.2178217822, n: 101, lb:0.0581) Worst: 8 (mean:0.0000, n: 1, ub:1.0000) B = 0.94\n",
      "Best: 0 (mean:0.1791044776, n: 201, lb:0.0654) Worst: 16 (mean:0.0000, n: 1, ub:1.0000) B = 0.93\n",
      "Best: 8 (mean:0.1584158416, n: 101, lb:0.0286) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 0.97\n",
      "Best: 8 (mean:0.1990049751, n: 201, lb:0.0761) Worst: 2 (mean:0.0000, n: 1, ub:1.0000) B = 0.92\n",
      "Best: 8 (mean:0.2059800664, n: 301, lb:0.0977) Worst: 3 (mean:0.0000, n: 1, ub:1.0000) B = 0.90\n",
      "Best: 3 (mean:0.2475247525, n: 101, lb:0.0686) Worst: 14 (mean:0.0000, n: 1, ub:1.0000) B = 0.93\n",
      "Best: 3 (mean:0.2189054726, n: 201, lb:0.0872) Worst: 13 (mean:0.0000, n: 1, ub:1.0000) B = 0.91\n",
      "Best: 3 (mean:0.2192691030, n: 301, lb:0.1059) Worst: 12 (mean:0.0000, n: 1, ub:1.0000) B = 0.89\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-0994261be991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcollectData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-5cdd1a982551>\u001b[0m in \u001b[0;36mcollectData\u001b[0;34m(parameter, times, precisions, n_trials)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAnchorImageMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'yeet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mcurrTime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anchor/ImageAnchors/anchor_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, image, classifier_fn, threshold, delta, tau, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m         exp = anchor_base.AnchorBaseBeam.anchor_beam(\n\u001b[1;32m    300\u001b[0m             \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             desired_confidence=threshold, coverage_samples=100,max_anchor_size=3,**kwargs)\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_exp_from_hoeffding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anchor/ImageAnchors/anchor/anchor_base.py\u001b[0m in \u001b[0;36manchor_beam\u001b[0;34m(sample_fn, delta, epsilon, batch_size, min_shared_samples, desired_confidence, beam_size, verbose, epsilon_stop, min_samples_start, max_anchor_size, verbose_every, stop_on_first, coverage_samples)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0msample_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 verbose=verbose, verbose_every=verbose_every)\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mbest_of_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchosen_tuples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anchor/ImageAnchors/anchor/anchor_base.py\u001b[0m in \u001b[0;36mlucb\u001b[0;34m(sample_fns, initial_stats, epsilon, delta, batch_size, top_n, verbose, verbose_every)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mut\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mut\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mut\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mn_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mpositives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msample_fns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anchor/ImageAnchors/anchor/anchor_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(n, t)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0msample_fns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcomplete_sample_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample_fns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anchor/ImageAnchors/anchor/anchor_base.py\u001b[0m in \u001b[0;36mcomplete_sample_fn\u001b[0;34m(t, n)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0msample_fns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcomplete_sample_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mcurrent_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'current_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# idxs = range(state['data'].shape[0], state['data'].shape[0] + n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anchor/ImageAnchors/anchor_image.py\u001b[0m in \u001b[0;36msample_fn_dummy\u001b[0;34m(present, num_samples, compute_labels)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                     \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;31m# pred = np.argmax(classifier_fn(temp.to_nn())[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2509\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2445\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;31m# may change to (mode, 0, 1) post-1.1.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MAPMODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2447\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2448\u001b[0m             im = im._new(\n\u001b[1;32m   2449\u001b[0m                 \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2348\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "collectData(parameter,times,precisions,n_trials = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dummy_precisions.pck', 'rb') as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[(26, '', 0.5273679200380771, [], 0),\n",
       "   (18, '', 0.8637532133676092, [], 0),\n",
       "   (8, '', 1.0, [], 0)],\n",
       "  [(26, '', 0.53218712514994, [], 0),\n",
       "   (18, '', 0.8824742268041237, [], 0),\n",
       "   (8, '', 1.0, [], 0)],\n",
       "  [(26, '', 0.5116623472787857, [], 0),\n",
       "   (18, '', 0.8738049713193117, [], 0),\n",
       "   (8, '', 1.0, [], 0)]],\n",
       " 1: [[(3, '', 0.2436738519212746, [], 0),\n",
       "   (8, '', 0.312, [], 0),\n",
       "   (12, '', 0.45316253002401924, [], 0)],\n",
       "  [(3, '', 0.2303498409813721, [], 0),\n",
       "   (8, '', 0.31791421362489486, [], 0),\n",
       "   (12, '', 0.43587946741415556, [], 0)]],\n",
       " 2: [],\n",
       " 3: [],\n",
       " 4: [],\n",
       " 5: [],\n",
       " 6: [],\n",
       " 7: [],\n",
       " 8: [],\n",
       " 9: []}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[(26, '', 0.5445458496305954, [], 0),\n",
       "   (18, '', 0.8918918918918919, [], 0),\n",
       "   (8, '', 1.0, [], 0)],\n",
       "  [(26, '', 0.4956268221574344, [], 0),\n",
       "   (18, '', 0.8444924406047516, [], 0),\n",
       "   (8, '', 1.0, [], 0)]],\n",
       " 1: [[(3, '', 0.23950419832067174, [], 0),\n",
       "   (8, '', 0.3297161936560935, [], 0),\n",
       "   (12, '', 0.44216089254257196, [], 0)],\n",
       "  [(3, '', 0.2438118811881188, [], 0),\n",
       "   (5, '', 0.3261802575107296, [], 0),\n",
       "   (16, '', 0.43095667870036103, [], 0)]],\n",
       " 2: [[(13, '', 0.5682878081279147, [], 0),\n",
       "   (8, '', 0.7701863354037267, [], 0),\n",
       "   (10, '', 0.9935897435897436, [], 0)],\n",
       "  [(13, '', 0.5602931379080613, [], 0),\n",
       "   (8, '', 0.7883495145631068, [], 0),\n",
       "   (10, '', 1.0, [], 0)]],\n",
       " 3: [],\n",
       " 4: [],\n",
       " 5: [],\n",
       " 6: [],\n",
       " 7: [],\n",
       " 8: [],\n",
       " 9: []}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
