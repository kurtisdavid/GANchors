{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import csgm\n",
    "import dcgan\n",
    "import skimage\n",
    "import anchor_image\n",
    "import image_utils\n",
    "import importlib\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'image_utils' from '/home/kurtis/Desktop/anchor/ImageAnchors/image_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(image_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {0: [3],\n",
    "        1: [2],\n",
    "        2: [1],\n",
    "        3: [18],\n",
    "        4: [4],\n",
    "        5: [8],\n",
    "        6: [11],\n",
    "        7: [0],\n",
    "        8: [61],\n",
    "        9: [7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = torchvision.datasets.MNIST('./', train=False, transform=lambda x: np.array(x)/255.,\n",
    "                                   target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 4.000000000000001\n",
      "NUM SEGMENTS 15\n",
      "15 3.18125\n",
      "NUM SEGMENTS 15\n",
      "15 4.000000000000001\n",
      "NUM SEGMENTS 15\n",
      "15 3.8000000000000007\n",
      "NUM SEGMENTS 15\n",
      "15 3.828125000000001\n",
      "NUM SEGMENTS 15\n",
      "15 3.712500000000001\n",
      "NUM SEGMENTS 15\n",
      "15 3.8000000000000007\n",
      "NUM SEGMENTS 15\n",
      "15 3.5000000000000004\n",
      "NUM SEGMENTS 15\n",
      "15 3.7000000000000006\n",
      "NUM SEGMENTS 15\n",
      "15 3.3500000000000005\n",
      "NUM SEGMENTS 15\n"
     ]
    }
   ],
   "source": [
    "for x in samples:\n",
    "    for c in samples[x]:\n",
    "        print(\"NUM SEGMENTS\", np.max(image_utils.create_segments(mnist_test[c][0])) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'dummy': {'dataset': mnist_test, 'dummys': mnist_test},\n",
    "    'batch': {'G': lambda x: dcgan.load_generator(eval=True), 'dataset': mnist_test, 'batch_norm': False},\n",
    "    'batchBN': {'G': lambda x: dcgan.load_generator(eval=False),'dataset': mnist_test, 'batch_norm': True}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = dcgan.Net()\n",
    "net.load_state_dict(torch.load('mnist_cnn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(images):\n",
    "    try:\n",
    "        images = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "    except:\n",
    "        pass\n",
    "    return net(images.view(images.shape[0],1,28,28)).data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = {\n",
    "    key: {i: [] for i in range(10)\n",
    "         }  for key in parameters}\n",
    "\n",
    "precisions = {key:{i: [] for i in range(10)}\n",
    "                 for key in parameters\n",
    "             }\n",
    "\n",
    "coverages = {key:{i: [] for i in range(10)}\n",
    "                 for key in parameters\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectData(parameter, times, precisions, n_trials = 1):\n",
    "#     n_trials = 1\n",
    "    currTime = times[parameter]\n",
    "    currPrecision = precisions[parameter]\n",
    "    currCoverage = coverages[parameter]\n",
    "    for c in samples:\n",
    "        sample = samples[c][0]\n",
    "        for i in range(n_trials):\n",
    "            image = mnist_test[sample][0]\n",
    "            explainer = anchor_image.AnchorImageMNIST([],'yeet', **parameters[parameter])\n",
    "            start = time.process_time()\n",
    "            coverage, segments, exp = explainer.explain_instance(image,predict_fn,verbose=True)\n",
    "            end = time.process_time()\n",
    "            currTime[c].append(end-start)\n",
    "            currPrecision[c].append(exp)\n",
    "            currCoverage[c].append(coverage)\n",
    "            with open(parameter+'_times.pck','wb') as f:\n",
    "                pickle.dump(currTime,f)\n",
    "            with open(parameter+'_precisions.pck','wb') as f:\n",
    "                pickle.dump(currPrecision,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = 'batchBN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 4.000000000000001\n",
      "True pred 0\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 11 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 10 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 9 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 2 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 8 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 3 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 6 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 4 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 5 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 7 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 11 (mean:0.9207920792, n: 101, lb:0.6917) Worst: 12 (mean:0.0000, n: 1, ub:1.0000) B = 0.31\n",
      "Best: 11 (mean:0.9402985075, n: 201, lb:0.8008) Worst: 13 (mean:0.0000, n: 1, ub:1.0000) B = 0.20\n",
      "Best: 11 (mean:0.9401993355, n: 301, lb:0.8319) Worst: 14 (mean:0.0000, n: 1, ub:1.0000) B = 0.17\n",
      "Best of size  1 :\n",
      "11 0.9501246882793017 0.9233082353393821 0.9700866851426122\n",
      "(11,) mean = 0.95 lb = 0.92 ub = 0.97 coverage: 0.49 n: 401\n",
      "Found eligible anchor  (11,) Coverage: 0.49 Is best? True\n",
      "Making tuples...\n",
      "15 4.000000000000001\n",
      "True pred 0\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 11 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 10 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 6 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 2 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 5 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 7 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 4 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 8 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 3 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 9 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 11 (mean:0.9603960396, n: 101, lb:0.7578) Worst: 12 (mean:0.0000, n: 1, ub:1.0000) B = 0.24\n",
      "Best: 11 (mean:0.9402985075, n: 201, lb:0.8008) Worst: 13 (mean:0.0000, n: 1, ub:1.0000) B = 0.20\n",
      "Best: 11 (mean:0.9468438538, n: 301, lb:0.8419) Worst: 14 (mean:0.0000, n: 1, ub:1.0000) B = 0.16\n",
      "Best of size  1 :\n",
      "11 0.9276807980049875 0.8966471657527684 0.9521965253565375\n",
      "(11,) mean = 0.93 lb = 0.90 ub = 0.95 coverage: 0.50 n: 401\n",
      "Making tuples...\n",
      "Best: 13 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 4 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 12 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 6 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 11 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:1.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 10 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:1.0000, n: 101, ub:1.0000) B = 1.00\n",
      "Best: 9 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:1.0000, n: 201, ub:1.0000) B = 1.00\n",
      "Best of size  2 :\n",
      "9 1.0 0.9774595396069665 1\n",
      "(7, 11) mean = 1.00 lb = 0.98 ub = 1.00 coverage: 0.23 n: 101\n",
      "Found eligible anchor  (7, 11) Coverage: 0.23 Is best? True\n",
      "Making tuples...\n",
      "15 4.000000000000001\n",
      "True pred 0\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 14 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 11 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 10 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 2 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 5 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 3 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 4 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 6 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 10 (mean:0.8910891089, n: 101, lb:0.6500) Worst: 7 (mean:0.0000, n: 1, ub:1.0000) B = 0.35\n",
      "Best: 10 (mean:0.8557213930, n: 201, lb:0.6844) Worst: 8 (mean:0.0000, n: 1, ub:1.0000) B = 0.32\n",
      "Best: 10 (mean:0.8604651163, n: 301, lb:0.7249) Worst: 9 (mean:0.0000, n: 1, ub:1.0000) B = 0.28\n",
      "Best: 10 (mean:0.8379052369, n: 401, lb:0.7174) Worst: 12 (mean:0.0000, n: 1, ub:1.0000) B = 0.28\n",
      "Best: 10 (mean:0.8383233533, n: 501, lb:0.7315) Worst: 13 (mean:0.0000, n: 1, ub:1.0000) B = 0.27\n",
      "Best: 11 (mean:0.8316831683, n: 101, lb:0.5656) Worst: 10 (mean:0.8220, n: 601, ub:0.8987) B = 0.33\n",
      "Best: 11 (mean:0.8905472637, n: 201, lb:0.7261) Worst: 10 (mean:0.8117, n: 701, ub:0.8859) B = 0.16\n",
      "Best of size  1 :\n",
      "11 0.9069767441860465 0.8669387795055663 0.9387611901379933\n",
      "(11,) mean = 0.91 lb = 0.87 ub = 0.94 coverage: 0.49 n: 301\n",
      "Making tuples...\n",
      "Best: 13 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 4 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 12 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:1.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 11 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:1.0000, n: 101, ub:1.0000) B = 1.00\n",
      "Best: 10 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:1.0000, n: 201, ub:1.0000) B = 1.00\n",
      "Best: 9 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 1 (mean:1.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 8 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 9 (mean:0.9901, n: 101, ub:1.0000) B = 1.00\n",
      "Best: 7 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 9 (mean:0.9950, n: 201, ub:1.0000) B = 1.00\n",
      "Best: 6 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 1 (mean:1.0000, n: 101, ub:1.0000) B = 1.00\n",
      "Best: 5 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 1 (mean:1.0000, n: 201, ub:1.0000) B = 1.00\n",
      "Best: 3 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 5 (mean:0.9901, n: 101, ub:1.0000) B = 1.00\n",
      "Best: 2 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 1 (mean:1.0000, n: 301, ub:1.0000) B = 1.00\n",
      "Best of size  2 :\n",
      "1 1.0 0.9942735316201349 1\n",
      "(5, 11) mean = 1.00 lb = 0.99 ub = 1.00 coverage: 0.27 n: 401\n",
      "Found eligible anchor  (5, 11) Coverage: 0.27 Is best? True\n",
      "Making tuples...\n",
      "15 3.18125\n",
      "True pred 1\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n",
      "Best: 14 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 0 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 12 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 1 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 11 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 2 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 10 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 4 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 9 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 6 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 8 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 7 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 5 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 13 (mean:0.0000, n: 1, ub:1.0000) B = 1.00\n",
      "Best: 3 (mean:1.0000000000, n: 1, lb:0.0000) Worst: 14 (mean:0.9802, n: 101, ub:1.0000) B = 1.00\n",
      "Best of size  1 :\n",
      "3 1.0 0.9774595396069665 1\n",
      "(3,) mean = 1.00 lb = 0.98 ub = 1.00 coverage: 0.50 n: 101\n",
      "Found eligible anchor  (3,) Coverage: 0.5 Is best? True\n",
      "Making tuples...\n",
      "15 3.18125\n",
      "True pred 1\n",
      "Taking coverage data...\n",
      "Checkpoint 1\n",
      "Making tuples...\n"
     ]
    }
   ],
   "source": [
    "collectData(parameter,times,precisions,n_trials = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('batchBN_precisions.pck', 'rb') as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[(11, '', 0.9329529243937232, [], 0), (7, '', 1.0, [], 0)],\n",
       "  [(11, '', 0.9317803660565723, [], 0), (7, '', 1.0, [], 0)],\n",
       "  [(11, '', 0.946843853820598, [], 0), (5, '', 1.0, [], 0)]],\n",
       " 1: [[], [], []],\n",
       " 2: [[(0, '', 0.8419301164725458, [], 0), (7, '', 1.0, [], 0)],\n",
       "  [(0, '', 0.8211788211788211, [], 0), (7, '', 1.0, [], 0)],\n",
       "  [(0, '', 0.8031383737517832, [], 0), (7, '', 1.0, [], 0)]],\n",
       " 3: [[],\n",
       "  [(5, '', 0.3932905067808708, [], 0),\n",
       "   (11, '', 0.9402985074626866, [], 0),\n",
       "   (8, '', 1.0, [], 0)],\n",
       "  []],\n",
       " 4: [[(8, '', 0.7066167290886392, [], 0), (0, '', 1.0, [], 0)],\n",
       "  [(8, '', 0.7162837162837162, [], 0),\n",
       "   (5, '', 0.9401993355481728, [], 0),\n",
       "   (0, '', 1.0, [], 0)],\n",
       "  [(8, '', 0.6907730673316709, [], 0), (0, '', 1.0, [], 0)]],\n",
       " 5: [[(3, '', 0.48951048951048953, [], 0), (6, '', 0.9603960396039604, [], 0)],\n",
       "  [(3, '', 0.5014985014985015, [], 0), (6, '', 0.9867109634551495, [], 0)],\n",
       "  [(3, '', 0.48501362397820164, [], 0), (6, '', 0.9900332225913622, [], 0)]],\n",
       " 6: [[(0, '', 0.6833095577746077, [], 0), (4, '', 0.9800995024875622, [], 0)],\n",
       "  [(0, '', 0.6866267465069861, [], 0), (9, '', 0.9900497512437811, [], 0)],\n",
       "  [(0, '', 0.7022977022977023, [], 0), (4, '', 1.0, [], 0)]],\n",
       " 7: [[(12, '', 0.8803986710963455, [], 0), (2, '', 1.0, [], 0)],\n",
       "  [(12, '', 0.8530670470756063, [], 0), (6, '', 1.0, [], 0)],\n",
       "  [(12, '', 0.8870431893687708, [], 0), (6, '', 1.0, [], 0)]],\n",
       " 8: [[], [], []],\n",
       " 9: [[(4, '', 0.9568106312292359, [], 0)],\n",
       "  [(4, '', 0.9451371571072319, [], 0), (1, '', 1.0, [], 0)],\n",
       "  [(4, '', 0.9501661129568106, [], 0)]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
